## Feeding Knowledge to LLMs (RAG)

I tried to generate philosophical response from a llm by feeding dataset as a knowledge base. Finally we build a bot which gives us structred response by marking key points and explaining it further.

I used Pinecone as vector DB, openai for llm and langchain as a framework

